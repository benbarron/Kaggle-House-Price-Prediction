---
title: "R Notebook"
output: html_notebook
---

## Load And Clean Data
```{r}

rm(list = ls())
setwd('~/Desktop/Kaggle_HousePrices')

library(tidyverse)
library(onehot)

## using read.csv because read_csv doesn't have stringsAsFactors Option
train.data <- as_tibble(read.csv('./train.csv', stringsAsFactors = T, header = T))
pred.data <- as_tibble(read.csv('./test.csv', stringsAsFactors = T, header = T))

pred.data$SalePrice <- 0
pred.data$Prediction <- T
train.data$Prediction <- F

data <- rbind(train.data, pred.data)
data <- data[sample(nrow(data)),]

levels(data$Fence) = c(levels(data$Fence), 'NoFence')
levels(data$Alley) = c(levels(data$Alley), 'NoAlley')

data <- mutate(data,
               Alley = replace_na(Alley, 'NoAlley'),
               Fence = replace_na(Fence, 'NoFence'),
               GarageQual = replace_na(GarageQual, 'TA'),
               GarageCond = replace_na(GarageCond, 'TA'),
               GarageType = replace_na(GarageType, 'Attchd'),
               GarageYrBlt = replace_na(GarageYrBlt, 1980),
               GarageFinish = replace_na(GarageFinish, 'Unf'),
               FireplaceQu = replace_na(FireplaceQu, 'Gd'),
               BsmtFinType2 = replace_na(BsmtFinType2, 'Unf'),
               BsmtFinType1 = replace_na(BsmtFinType1, 'Unf'),
               BsmtExposure = replace_na(BsmtExposure, 'No'),
               MasVnrArea = replace_na(MasVnrArea, 103),
               MasVnrType = replace_na(MasVnrType, 'None'),
               LotFrontage = replace_na(LotFrontage, 70),
               BsmtCond = replace_na(BsmtCond, 'TA'),
               SaleType = replace_na(SaleType, 'WD'),
               GarageArea = replace_na(GarageArea, 472),
               Functional = replace_na(Functional, 'Typ'),
               GarageCars = replace_na(GarageCars, 2),
               BsmtHalfBath = replace_na(BsmtHalfBath, 0),
               BsmtFullBath = replace_na(BsmtFullBath, 0),
               BsmtFinSF1 = replace_na(BsmtFinSF1, 439),
               BsmtFinSF2 = replace_na(BsmtFinSF2, 52),
               BsmtUnfSF = replace_na(BsmtUnfSF, 554),
               TotalBsmtSF = replace_na(TotalBsmtSF, 1046),
               Exterior2nd = replace_na(Exterior2nd, 'VinylSd'),
               BsmtQual = replace_na(BsmtQual, 'Gd'),
               Exterior1st = replace_na(Exterior1st, 'VinylSd'),
               MSZoning = replace_na(MSZoning, 'RL'),
               Electrical = replace_na(Electrical, 'SBrkr'),
               KitchenQual = replace_na(KitchenQual, 'TA'))

data <- select(data, -c('MiscFeature', 'Utilities', 'PoolQC'))
##'BsmtExposure', 'BsmtFinType1','WoodDeckSF','OpenPorchSF','Fireplaces'

train.data <- filter(data, Prediction == F) %>% select(-c('Prediction'))
pred.data <- filter(data, Prediction == T) %>% select(-c('Prediction'))

set.seed(2345)
case.select <- sample(1:nrow(train.data), nrow(train.data)*0.9)
data.train <- train.data[case.select, ]
data.test <- train.data[-case.select, ]

## one hot encoded version of data
encoder <- onehot(data, max_levels = 30)
data.hot <- as_tibble(predict(encoder, data))
train.hot <- filter(data.hot, Prediction == F) %>% select(-c('Prediction'))
pred.hot <- filter(data.hot, Prediction == T) %>% select(-c('Prediction'))

ncols <- ncol(train.hot)
ncms <- ncols - 1
x.train <- as.matrix(train.hot[case.select, 2:ncms])
x.test <- as.matrix(train.hot[-case.select, 2:ncms])
y.train <- as.matrix(train.hot[case.select,  ncols])
y.test <- as.matrix(train.hot[-case.select, ncols])
pred.mat <- as.matrix(pred.hot[, 2:ncms])

```

## RF, XGB, SVM
```{r}

library(randomForest)
library(xgboost)
library(e1071)


## fit the model
rf.fit <- randomForest(SalePrice~., data = data.train[,2:ncol(data.train)], ntree = 500)
svm.fit <- svm(SalePrice~., data = data.train[,2:ncol(data.train)])
xgb.fit <- xgboost(data = x.train, label = y.train, nrounds = 400,
                   params = list(max_depth = 2, eta = 0.05, lambda = 0.15))

```

## Standardize Data For NN
```{r}

library(stringr)

cnames <- colnames(x.train)
num.cols <- which(is.na(str_locate(cnames, '=')[,2]))

m <- colMeans(x.train[,num.cols])
s <- apply(x.train[,num.cols], 2, sd)

x.test.scaled <- x.test
x.train.scaled <- x.train
pred.mat.scaled <- pred.mat

x.train.scaled[, num.cols] <- scale(x.train[, num.cols], center = m, scale = s)
x.test.scaled[, num.cols] <- scale(x.test[, num.cols], center = m, scale = s)
pred.mat.scaled[, num.cols] <- scale(pred.mat[, num.cols], center = m, scale = s)

```

## Keras NN
```{r}

#library(keras)

nn.model <- keras_model_sequential()

nn.model %>% 
  layer_dense(units = 512, activation = 'relu', input_shape = ncol(x.train.scaled)) %>% 
  layer_dropout(rate = 0.1) %>% 
  layer_dense(units = 256, activation = 'relu') %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dense(units = 64, activation = 'relu') %>%
  layer_dense(units = 1, activation = 'relu')

compile(nn.model, loss = 'mae', optimizer = optimizer_rmsprop(lr = 0.0015), metrics = c('mae'))

hist <- fit(nn.model, x = x.train.scaled, y = y.train, 
            epochs = 20, batch_size = 64, 
            validation_data = list(x.test.scaled, y.test))

pred <- predict(nn.model, x.test.scaled)
obs <- y.test
pred.log <- log(pred)
obs.log <- log(obs)
plot(pred, obs)
abline(0, 1, col = 'red')
sqrt(mean((pred.log - obs.log)^2))
sqrt(mean((pred - obs)^2))

```


## Test Models
```{r}

## test the model
xgb.pred <- predict(xgb.fit, x.test)
rf.pred <- predict(rf.fit, data.test[,2:ncol(data.test)])
svm.pred <- predict(svm.fit, data.test[,2:ncol(data.test)])
nn.pred <- predict(nn.model, x.test.scaled)

res <- tibble(xgb = xgb.pred, rf = rf.pred, svm = svm.pred, nn = nn.pred)
res$avg <- (res$xgb + res$rf + res$svm + res$nn) / 4

obs <- y.test   
obs.log <- log(obs)
pred.log <- log(res$avg)
pred <- res$avg

plot(pred, obs)               
abline(0, 1, col = 'red')            
mean(abs(pred - obs))     
sqrt(mean((pred - obs)^2)) 
sqrt(mean((pred.log - obs.log)^2))


```

## Create Submission
```{r}

## train model using all of data
xgb.fit <- xgboost(data = as.matrix(train.hot[, 2:ncms]),label = as.matrix(train.hot[, ncols]), 
                   nrounds = 500, params = list(max_depth = 2, eta = 0.05, lambda = 0.15))
rf.fit <- randomForest(SalePrice~., data = train.data[,2:ncol(train.data)], ntree = 500) 
svm.fit <- svm(SalePrice~., data = train.data[,2:ncol(train.data)])

xgb.pred <- predict(xgb.fit, pred.mat)
rf.pred <- predict(rf.fit, pred.data[,2:ncol(pred.data)])
svm.pred <- predict(svm.fit, pred.data[,2:ncol(pred.data)])
nn.pred <- predict(nn.model, pred.mat.scaled)

res <- tibble(xgb = xgb.pred, rf = rf.pred, svm = svm.pred, nn = nn.pred)
res$avg <- (res$xgb + res$rf + res$svm + res$nn) / 4

```

```{r}

#sub <- tibble(Id = pred.data$Id, SalePrice = predict(rf.fit, pred.data))
sub <- tibble(Id = pred.data$Id, SalePrice = res$avg)
write.csv(sub, './sub9.csv', row.names = F)
sub

```


## Compare Submissions
```{r}

t1 <- read_csv('./sub6.csv')
t2 <- read_csv('./sub7.csv')
t3 <- read_csv('./sub8.csv')
t4 <- read_csv('./sub9.csv')

plot(t3$SalePrice, t4$SalePrice)

```










